{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from influxdb_client import InfluxDBClient, Point, WriteOptions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1. CONFIGURATION\n",
    "# ============================================================\n",
    "INFLUX_URL                  = \"http://100.107.165.205:8086/\"\n",
    "INFLUX_TOKEN                = \"SBto4EBQvq7wY-APYOoDn4QpYZ9GkjWzQZzftrDDk31kjRYWYN-37i7uHNXddkZjYsAU85EdYbI2hoKBLB1woA==\"\n",
    "INFLUX_ORG                  = \"e35fd59963c483cd\"\n",
    "INFLUX_BUCKET_CORRIDOR      = \"1_1_1\"\n",
    "INFLUX_BUCKET_BATHROOM      = \"1_2_6\"\n",
    "INFLUX_BUCKET_KITCHEN       = \"1_4_10\"\n",
    "INFLUX_BUCKET_AUTH          = \"\"\n",
    "\n",
    "CONFIG_STAY_MAX_INTERVAL    = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-09T13:15:22.882441500Z",
     "start_time": "2025-12-09T13:15:22.873857500Z"
    }
   },
   "id": "856b5d4057dab0fd"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. CONNECT TO INFLUXDB\n",
    "# ============================================================\n",
    "def get_client():\n",
    "    return InfluxDBClient(\n",
    "        url=INFLUX_URL,\n",
    "        token=INFLUX_TOKEN,\n",
    "        org=INFLUX_ORG\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. QUERY DATA FROM INFLUXDB\n",
    "# ============================================================\n",
    "def query_data(device_id=1, range_in_hours=6):\n",
    "    query_api = client.query_api()\n",
    "    MEASUREMENT_PIR = \"PIR\"\n",
    "\n",
    "    if device_id == 1:\n",
    "        bucket = INFLUX_BUCKET_CORRIDOR\n",
    "    elif device_id == 2:\n",
    "        bucket = INFLUX_BUCKET_BATHROOM\n",
    "    elif device_id == 4:\n",
    "        bucket = INFLUX_BUCKET_KITCHEN\n",
    "    else:\n",
    "        print(\"Unknown device ID.\")\n",
    "        return\n",
    "\n",
    "    # query = f'''\n",
    "    #     from(bucket: \"{bucket}\")\n",
    "    #       |> range(start: -{range_in_hours}h)\n",
    "    #       |> filter(fn: (r) => r[\"_measurement\"] == \"{MEASUREMENT_PIR}\")\n",
    "    #       |> keep(columns: [\"_time\", \"_value\", \"_field\", \"_measurement\"])\n",
    "    # '''\n",
    "\n",
    "    query = f'''\n",
    "           from(bucket: \"{bucket}\")\n",
    "             |> range(start: 2025-12-01T00:00:00Z, stop: 2025-12-01T23:59:59Z)\n",
    "             |> filter(fn: (r) => r[\"_measurement\"] == \"{MEASUREMENT_PIR}\")\n",
    "             |> keep(columns: [\"_time\", \"_value\", \"_field\", \"_measurement\"])\n",
    "       '''\n",
    "\n",
    "    print(\"Running query...\")\n",
    "    df = query_api.query_data_frame(query)\n",
    "\n",
    "    # If Influx returns multiple tables, flatten them\n",
    "    if isinstance(df, list):\n",
    "        df = pd.concat(df, ignore_index=True)\n",
    "\n",
    "    print(f\"Retrieved {len(df)} rows.\")\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-09T13:49:58.496520200Z",
     "start_time": "2025-12-09T13:49:58.495512300Z"
    }
   },
   "id": "ef189d73f95fdf4c"
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def add_to_df(df, start_time, latest_time, room):\n",
    "    duration = pd.Timedelta(seconds=0) if latest_time is None else latest_time - start_time\n",
    "    print(f\"Duration: {duration.seconds}\")\n",
    "    df.loc[len(df)] = [room, start_time, duration.seconds] \n",
    "\n",
    "def analyze_stays(df: pd.DataFrame):\n",
    "    print(\"\\nAnalyzing stays...\")\n",
    "    if df.empty:\n",
    "        print(\"\\nEmpty dataframe.\")\n",
    "        return df\n",
    "    \n",
    "    room = df.loc[0, '_value']\n",
    "    \n",
    "    df_stays = pd.DataFrame({\n",
    "        \"room\": [],\n",
    "        \"start_time\": [],\n",
    "        \"duration\": []\n",
    "    })\n",
    "    \n",
    "    df.sort_values(by=\"_time\") # ascending by default\n",
    "    time_array = df[\"_time\"]\n",
    "    start_time = df.loc[0, '_time'] # type: pd.Timestamp\n",
    "    print(f\"Start time: {start_time}\")\n",
    "    \n",
    "    print(f\"Type of start_time_str: {type(start_time)}\")\n",
    "    latest_time = None\n",
    "    for idx, event_time in enumerate(time_array[1:]):\n",
    "        time_passed = event_time - start_time\n",
    "        # Check if event is part of the same stay\n",
    "        if time_passed < timedelta(minutes=CONFIG_STAY_MAX_INTERVAL):\n",
    "            # If part of stay, extend latest_time to current event_time and continue with next event\n",
    "            latest_time = event_time\n",
    "            continue\n",
    "        else:\n",
    "            # If not, write stay to df and set current event_time as new start_time\n",
    "            add_to_df(df_stays, start_time, latest_time, room)\n",
    "            # Reset start_time & latest_time\n",
    "            latest_time = None\n",
    "            start_time = event_time\n",
    "    \n",
    "    if start_time is not None:\n",
    "        add_to_df(df_stays, start_time, latest_time, room)\n",
    "    return df_stays"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-09T14:34:37.188157900Z",
     "start_time": "2025-12-09T14:34:37.185537300Z"
    }
   },
   "id": "eab570c735e234a1"
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. WRITE RESULTS BACK TO INFLUXDB\n",
    "# ============================================================\n",
    "def write_results(df_stays: pd.DataFrame):\n",
    "    print(\"\\nWriting results to InfluxDB...\")\n",
    "\n",
    "    # Convert start_time to datetime (required by InfluxDB)\n",
    "    df_stays[\"start_time\"] = pd.to_datetime(df_stays[\"start_time\"])\n",
    "    # Set the timestamp column as index â€” InfluxDB uses the index as time\n",
    "    df_stays = df_stays.set_index(\"start_time\")\n",
    "\n",
    "    write_api = client.write_api()\n",
    "    \n",
    "    print(\"\\nData is ready to be written into DB:\")\n",
    "    print(df_stays)\n",
    "\n",
    "    # Write DataFrame to InfluxDB\n",
    "    write_api.write(\n",
    "        bucket=\"stays\",\n",
    "        record=df_stays,\n",
    "        data_frame_measurement_name=\"room_stays\",  # measurement name\n",
    "        data_frame_tag_columns=[\"room\"]  # \"room\" becomes a tag\n",
    "    )\n",
    "\n",
    "    print(\"Data written successfully to bucket 'stays'\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-09T14:36:21.643565Z",
     "start_time": "2025-12-09T14:36:21.632047900Z"
    }
   },
   "id": "78f8df1b86f5034a"
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to InfluxDB...\n",
      "Running query...\n",
      "Retrieved 148 rows.\n",
      "\n",
      "Found 148 rows of data\n",
      "\n",
      "Analyzing stays...\n",
      "Start time: 2025-12-01 00:00:49+00:00\n",
      "Type of start_time_str: <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "Duration: 524\n",
      "Duration: 11\n",
      "Duration: 589\n",
      "Duration: 72\n",
      "Duration: 129\n",
      "Duration: 0\n",
      "Duration: 558\n",
      "Duration: 0\n",
      "Duration: 0\n",
      "Duration: 587\n",
      "Duration: 15\n",
      "Duration: 393\n",
      "Duration: 0\n",
      "Duration: 71\n",
      "Duration: 17\n",
      "Duration: 45\n",
      "Duration: 15\n",
      "Duration: 573\n",
      "Duration: 508\n",
      "Duration: 585\n",
      "Duration: 314\n",
      "Duration: 181\n",
      "Duration: 8\n",
      "Duration: 526\n",
      "Duration: 19\n",
      "Duration: 64\n",
      "Duration: 0\n",
      "Duration: 0\n",
      "\n",
      "Writing results to InfluxDB...\n",
      "\n",
      "Data is ready to be written into DB:\n",
      "                               room  duration\n",
      "start_time                                   \n",
      "2025-12-01 00:00:49+00:00  corridor       524\n",
      "2025-12-01 04:26:49+00:00  corridor        11\n",
      "2025-12-01 04:45:23+00:00  corridor       589\n",
      "2025-12-01 04:55:44+00:00  corridor        72\n",
      "2025-12-01 08:45:48+00:00  corridor       129\n",
      "2025-12-01 10:54:52+00:00  corridor         0\n",
      "2025-12-01 11:14:18+00:00  corridor       558\n",
      "2025-12-01 12:36:26+00:00  corridor         0\n",
      "2025-12-01 14:57:56+00:00  corridor         0\n",
      "2025-12-01 15:14:02+00:00  corridor       587\n",
      "2025-12-01 15:24:26+00:00  corridor        15\n",
      "2025-12-01 15:34:34+00:00  corridor       393\n",
      "2025-12-01 15:51:16+00:00  corridor         0\n",
      "2025-12-01 16:08:35+00:00  corridor        71\n",
      "2025-12-01 16:24:43+00:00  corridor        17\n",
      "2025-12-01 16:48:52+00:00  corridor        45\n",
      "2025-12-01 16:59:36+00:00  corridor        15\n",
      "2025-12-01 17:27:10+00:00  corridor       573\n",
      "2025-12-01 17:37:34+00:00  corridor       508\n",
      "2025-12-01 17:48:17+00:00  corridor       585\n",
      "2025-12-01 17:58:17+00:00  corridor       314\n",
      "2025-12-01 19:26:21+00:00  corridor       181\n",
      "2025-12-01 20:13:46+00:00  corridor         8\n",
      "2025-12-01 20:32:04+00:00  corridor       526\n",
      "2025-12-01 20:50:38+00:00  corridor        19\n",
      "2025-12-01 23:22:14+00:00  corridor        64\n",
      "2025-12-01 23:33:33+00:00  corridor         0\n",
      "2025-12-01 23:45:52+00:00  corridor         0\n",
      "Data written successfully to bucket 'stays'\n",
      "\n",
      "Pipeline finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\OneDrive\\Uni\\Master\\2025WS\\IoT Praktikum\\PIR Template - Base Code\\scripts\\venv\\Lib\\site-packages\\influxdb_client\\client\\warnings.py:31: MissingPivotFunction: The query doesn't contains the pivot() function.\n",
      "\n",
      "The result will not be shaped to optimal processing by pandas.DataFrame. Use the pivot() function by:\n",
      "\n",
      "    \n",
      "           from(bucket: \"1_1_1\")\n",
      "             |> range(start: 2025-12-01T00:00:00Z, stop: 2025-12-01T23:59:59Z)\n",
      "             |> filter(fn: (r) => r[\"_measurement\"] == \"PIR\")\n",
      "             |> keep(columns: [\"_time\", \"_value\", \"_field\", \"_measurement\"])\n",
      "        |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
      "\n",
      "You can disable this warning by:\n",
      "    import warnings\n",
      "    from influxdb_client.client.warnings import MissingPivotFunction\n",
      "\n",
      "    warnings.simplefilter(\"ignore\", MissingPivotFunction)\n",
      "\n",
      "For more info see:\n",
      "    - https://docs.influxdata.com/resources/videos/pivots-in-flux/\n",
      "    - https://docs.influxdata.com/flux/latest/stdlib/universe/pivot/\n",
      "    - https://docs.influxdata.com/flux/latest/stdlib/influxdata/influxdb/schema/fieldsascols/\n",
      "\n",
      "  warnings.warn(message, MissingPivotFunction)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6. MAIN PIPELINE\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Connecting to InfluxDB...\")\n",
    "    client = get_client()\n",
    "\n",
    "    device_id = 1\n",
    "    range_in_hours = 6\n",
    "\n",
    "    df = query_data(device_id=device_id, range_in_hours=range_in_hours)\n",
    "    print(f\"\\nFound {df.shape[0]} rows of data\")\n",
    "    df_stays = analyze_stays(df)\n",
    "    write_results(df_stays)\n",
    "\n",
    "    print(\"\\nPipeline finished.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-12-09T14:36:24.531202400Z",
     "start_time": "2025-12-09T14:36:24.432619100Z"
    }
   },
   "id": "64fa8f1b4e78523a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
