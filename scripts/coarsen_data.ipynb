{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef189d73f95fdf4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T09:23:16.972014300Z",
     "start_time": "2025-12-11T09:23:16.924167Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'influxdb_client'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minfluxdb_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InfluxDBClient\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m timedelta\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'influxdb_client'"
     ]
    }
   ],
   "source": [
    "from influxdb_client import InfluxDBClient\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "\n",
    "# ============================================================\n",
    "# 1. CONFIGURATION\n",
    "# ============================================================\n",
    "INFLUX_URL = \"http://100.107.165.205:8086/\"\n",
    "INFLUX_TOKEN = \"SBto4EBQvq7wY-APYOoDn4QpYZ9GkjWzQZzftrDDk31kjRYWYN-37i7uHNXddkZjYsAU85EdYbI2hoKBLB1woA==\"\n",
    "INFLUX_ORG = \"e35fd59963c483cd\"\n",
    "INFLUX_BUCKET_CORRIDOR = \"1_1_1\"\n",
    "INFLUX_BUCKET_BATHROOM = \"1_2_6\"\n",
    "INFLUX_BUCKET_KITCHEN = \"1_4_10\"\n",
    "INFLUX_BUCKET_AUTH = \"\"\n",
    "\n",
    "CONFIG_STAY_MAX_INTERVAL = 10\n",
    "\n",
    "\n",
    "def get_bucket_from_device(device_id: int):\n",
    "    if device_id == 1:\n",
    "        bucket = INFLUX_BUCKET_CORRIDOR\n",
    "    elif device_id == 2:\n",
    "        bucket = INFLUX_BUCKET_BATHROOM\n",
    "    elif device_id == 4:\n",
    "        bucket = INFLUX_BUCKET_KITCHEN\n",
    "    else:\n",
    "        print(\"Unknown device ID.\")\n",
    "        return None\n",
    "    return bucket\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2. CONNECT TO INFLUXDB\n",
    "# ============================================================\n",
    "def get_client():\n",
    "    return InfluxDBClient(\n",
    "        url=INFLUX_URL,\n",
    "        token=INFLUX_TOKEN,\n",
    "        org=INFLUX_ORG\n",
    "    )\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3. QUERY DATA FROM INFLUXDB\n",
    "# ============================================================\n",
    "def query_data(device_id=1,  start=None, stop=None, range_in_hours=None):\n",
    "    query_api = client.query_api()\n",
    "    MEASUREMENT_PIR = \"PIR\"\n",
    "\n",
    "    if device_id == 1:\n",
    "        bucket = INFLUX_BUCKET_CORRIDOR\n",
    "    elif device_id == 2:\n",
    "        bucket = INFLUX_BUCKET_BATHROOM\n",
    "    elif device_id == 4:\n",
    "        bucket = INFLUX_BUCKET_KITCHEN\n",
    "    else:\n",
    "        print(\"Unknown device ID.\")\n",
    "        return\n",
    "\n",
    "    if start is not None and stop is not None:\n",
    "        query = f'''\n",
    "               from(bucket: \"{bucket}\")\n",
    "                 |> range(start: {start}, stop: {stop})\n",
    "                 |> filter(fn: (r) => r[\"_measurement\"] == \"{MEASUREMENT_PIR}\")\n",
    "                 |> keep(columns: [\"_time\", \"_value\", \"_field\", \"_measurement\"])\n",
    "           '''\n",
    "       ###### |> pivot(rowKey: [\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\") ############\n",
    "    elif range_in_hours is not None:\n",
    "        query = f'''\n",
    "            from(bucket: \"{bucket}\")\n",
    "              |> range(start: -{range_in_hours}h)\n",
    "              |> filter(fn: (r) => r[\"_measurement\"] == \"{MEASUREMENT_PIR}\")\n",
    "              |> keep(columns: [\"_time\", \"_value\", \"_field\", \"_measurement\"])\n",
    "        '''\n",
    "    else:\n",
    "        print(\"You need to provide either start and stop time or a range in hours.\")\n",
    "        return pd.DataFrame({})\n",
    "\n",
    "    print(\"Running query...\")\n",
    "    df = query_api.query_data_frame(query)\n",
    "\n",
    "    # If Influx returns multiple tables, flatten them\n",
    "    if isinstance(df, list):\n",
    "        df = pd.concat(df, ignore_index=True)\n",
    "\n",
    "    print(f\"Retrieved {len(df)} rows.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4. PROCESS DATA\n",
    "# ============================================================\n",
    "def add_to_df(df, start_time, latest_time, room):\n",
    "    duration = pd.Timedelta(seconds=0) if latest_time is None else latest_time - start_time\n",
    "    print(f\"Duration: {duration.seconds}\")\n",
    "    df.loc[len(df)] = [room, start_time, duration.seconds]\n",
    "\n",
    "\n",
    "def analyze_stays(df: pd.DataFrame):\n",
    "    print(\"\\nAnalyzing stays...\")\n",
    "    if df.empty:\n",
    "        print(\"\\nEmpty dataframe.\")\n",
    "        return df\n",
    "\n",
    "    room = df.loc[0, '_value']\n",
    "\n",
    "    df_stays = pd.DataFrame({\n",
    "        \"room\": [],\n",
    "        \"start_time\": [],\n",
    "        \"duration\": []\n",
    "    })\n",
    "\n",
    "    df.sort_values(by=\"_time\")  # ascending by default\n",
    "    time_array = df[\"_time\"]\n",
    "    start_time = df.loc[0, '_time']  # type: pd.Timestamp\n",
    "    print(f\"Start time: {start_time}\")\n",
    "\n",
    "    print(f\"Type of start_time_str: {type(start_time)}\")\n",
    "    latest_time = None\n",
    "    for idx, event_time in enumerate(time_array[1:]):\n",
    "        time_passed = event_time - start_time\n",
    "        # Check if event is part of the same stay\n",
    "        if time_passed < timedelta(minutes=CONFIG_STAY_MAX_INTERVAL):\n",
    "            # If part of stay, extend latest_time to current event_time and continue with next event\n",
    "            latest_time = event_time\n",
    "            continue\n",
    "        else:\n",
    "            # If not, write stay to df and set current event_time as new start_time\n",
    "            add_to_df(df_stays, start_time, latest_time, room)\n",
    "            # Reset start_time & latest_time\n",
    "            latest_time = None\n",
    "            start_time = event_time\n",
    "\n",
    "    if start_time is not None:\n",
    "        add_to_df(df_stays, start_time, latest_time, room)\n",
    "    return df_stays\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5. WRITE RESULTS BACK TO INFLUXDB\n",
    "# ============================================================\n",
    "def write_results(df_stays: pd.DataFrame):\n",
    "    print(\"\\nWriting results to InfluxDB...\")\n",
    "\n",
    "    # Convert start_time to datetime (required by InfluxDB)\n",
    "    df_stays[\"start_time\"] = pd.to_datetime(df_stays[\"start_time\"])\n",
    "    # Set the timestamp column as index â€” InfluxDB uses the index as time\n",
    "    df_stays = df_stays.set_index(\"start_time\")\n",
    "\n",
    "    write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "\n",
    "    print(\"\\nData is ready to be written into DB:\")\n",
    "    print(df_stays)\n",
    "\n",
    "    # Write DataFrame to InfluxDB\n",
    "    write_api.write(\n",
    "        bucket=\"stays\",\n",
    "        record=df_stays,\n",
    "        data_frame_measurement_name=\"room_stays\",  # measurement name\n",
    "        data_frame_tag_columns=[\"room\"]  # \"room\" becomes a tag\n",
    "    )\n",
    "\n",
    "    print(\"Data written successfully to bucket 'stays'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64fa8f1b4e78523a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-11T11:12:25.673314900Z",
     "start_time": "2025-12-11T11:12:25.597814Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to InfluxDB...\n",
      "Running query...\n",
      "Retrieved 89 rows.\n",
      "\n",
      "Found 89 rows of data\n",
      "\n",
      "Analyzing stays...\n",
      "Start time: 2025-12-03 15:53:25+00:00\n",
      "Type of start_time_str: <class 'pandas._libs.tslibs.timestamps.Timestamp'>\n",
      "Duration: 478\n",
      "Duration: 566\n",
      "Duration: 0\n",
      "Duration: 80\n",
      "Duration: 579\n",
      "Duration: 182\n",
      "Duration: 309\n",
      "Duration: 189\n",
      "Duration: 130\n",
      "\n",
      "Writing results to InfluxDB...\n",
      "\n",
      "Data is ready to be written into DB:\n",
      "                              room  duration\n",
      "start_time                                  \n",
      "2025-12-03 15:53:25+00:00  kitchen       478\n",
      "2025-12-03 16:37:09+00:00  kitchen       566\n",
      "2025-12-03 16:47:54+00:00  kitchen         0\n",
      "2025-12-03 17:05:43+00:00  kitchen        80\n",
      "2025-12-03 17:17:40+00:00  kitchen       579\n",
      "2025-12-03 17:27:59+00:00  kitchen       182\n",
      "2025-12-03 17:43:24+00:00  kitchen       309\n",
      "2025-12-04 13:31:17+00:00  kitchen       189\n",
      "2025-12-04 13:42:44+00:00  kitchen       130\n",
      "Data written successfully to bucket 'stays'\n",
      "\n",
      "Pipeline finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\julia\\OneDrive\\Uni\\Master\\2025WS\\IoT Praktikum\\PIR Template - Base Code\\scripts\\venv\\Lib\\site-packages\\influxdb_client\\client\\warnings.py:31: MissingPivotFunction: The query doesn't contains the pivot() function.\n",
      "\n",
      "The result will not be shaped to optimal processing by pandas.DataFrame. Use the pivot() function by:\n",
      "\n",
      "    \n",
      "               from(bucket: \"1_4_10\")\n",
      "                 |> range(start: 2025-12-01T00:00:00Z, stop: 2025-12-10T23:59:59Z)\n",
      "                 |> filter(fn: (r) => r[\"_measurement\"] == \"PIR\")\n",
      "                 |> keep(columns: [\"_time\", \"_value\", \"_field\", \"_measurement\"])\n",
      "            |> pivot(rowKey:[\"_time\"], columnKey: [\"_field\"], valueColumn: \"_value\")\n",
      "\n",
      "You can disable this warning by:\n",
      "    import warnings\n",
      "    from influxdb_client.client.warnings import MissingPivotFunction\n",
      "\n",
      "    warnings.simplefilter(\"ignore\", MissingPivotFunction)\n",
      "\n",
      "For more info see:\n",
      "    - https://docs.influxdata.com/resources/videos/pivots-in-flux/\n",
      "    - https://docs.influxdata.com/flux/latest/stdlib/universe/pivot/\n",
      "    - https://docs.influxdata.com/flux/latest/stdlib/influxdata/influxdb/schema/fieldsascols/\n",
      "\n",
      "  warnings.warn(message, MissingPivotFunction)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6. MAIN PIPELINE\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Connecting to InfluxDB...\")\n",
    "    client = get_client()\n",
    "\n",
    "    device_id = 4\n",
    "    # range_in_hours = 6\n",
    "    start = \"2025-12-01T00:00:00Z\"\n",
    "    stop = \"2025-12-10T23:59:59Z\"\n",
    "\n",
    "    df = query_data(device_id=device_id, start=start, stop=stop)\n",
    "    print(f\"\\nFound {df.shape[0]} rows of data\")\n",
    "    df_stays = analyze_stays(df)\n",
    "    write_results(df_stays)\n",
    "\n",
    "    print(\"\\nPipeline finished.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
